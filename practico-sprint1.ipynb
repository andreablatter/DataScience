{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install seaborn \n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imports para entrenamiento, predicción y evaluación del modelo ####\n",
    "#### NO QUITAR ####\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#### Código Agregado ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading Data\n",
    "data = pd.read_csv('/home/bandrea/Documents/repos/DataScience/data/norech4w_20190908_abt_data.txt',sep='|')\n",
    "tag = pd.read_csv('/home/bandrea/Documents/repos/DataScience/data/norech4w_20190908_abt_tag.txt',sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparamos el tag y el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Observo que los campos SUSCRIBER_KEY tienen distinto formato en ambos data sets\n",
    "Verifico si los 6 primeros digitos del campo SUSCRIBER_KEY en tag son todos iguales.\n",
    "'''\n",
    "tmp = tag['SUSCRIBER_KEY'].str[:6]\n",
    "tmp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como sí son todos iguales y no aportan información los elimino para que coincidan con los del dataset data\n",
    "tag['SUSCRIBER_KEY'] = tag['SUSCRIBER_KEY'].str[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Por conocimiento de negocio se sabe que las columnas que contienen las letras AMT no son necesarias, \n",
    "asi que las borramos con un bucle for.\n",
    "'''\n",
    "tag.drop(columns=[x for x in tag.columns if 'AMT' in x],inplace=True)\n",
    "tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una nueva columna llamada total, que suma los  valores de las recargas acumuladas por semana. \n",
    "#Con axis=1 le decimos a sum() que la suma es por registro y no por columna\n",
    "tag['Total'] = tag[tag.columns[1:]].sum(axis=1)\n",
    "tag['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entonces ahora borramos todas las columnas que contenga EVT, que son la cantidad de recargas acumuladas por semana, \n",
    "#al tener su valor acumulado ya estas columnas no nos sirven\n",
    "tag.drop(columns=[x for x in tag.columns if 'EVT' in x],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos a guardar en total, false para todos aquellos cuya sumatoria sea 0, y true para los que tengan un total mayor a 1 \n",
    "tag['Total']=tag['Total']<1\n",
    "tag['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renombramos la columna total por target\n",
    "tag.rename(columns={'Total':'Target'},inplace=True)\n",
    "tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en vez de tenerlo como true o false es mas correcto manejarlo como 0s y 1s \n",
    "tag['Target'] = tag['Target'].astype(int)\n",
    "tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y ahora vamos a mergear esta tabla con la tabla data \n",
    "# no habria ocurrencias de esta manera pq en data no modificamos el suscriber key entonces nunca se encontrarian dos iguales\n",
    "#es por eso que agrego la celda de arriba con data['SUSCRIBER_KEY'] = data['SUSCRIBER_KEY'].str[6:]\n",
    "fulldata = data.merge(tag, on='SUSCRIBER_KEY')\n",
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con este comando vemos cantidad de filas x columnas, ahora tenemos una columna mas en la tabla data, la columna target\n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tras haber hecho el merge de ambas tablas eliminamos los dataframes data y tag\n",
    "del tag\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Comprobemos columnas innecesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas que no aportan nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#veremos aquellas columnas que tienen el mismo valor en todas las filas (un unico valor, por eso el 1)\n",
    "#entonces sabremos que estas columnas no aportan nada\n",
    "[x for x in fulldata.columns if fulldata[x].nunique()==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por conocimiento de Dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#por lo que ya nos dice el enunciado vamos a eliminar todas las columnas que no se usan según conocimiento del negocio\n",
    "to_remove=[\"SPNDG_VOI_ONNET_ARPU_M1\",\n",
    "\"SPNDG_VOI_ONNET_ARPU_M2\",\n",
    "\"SPNDG_VOI_ONNET_ARPU_M3\",\n",
    "\"SPNDG_VOI_OFFNET_ARPU_M1\",\n",
    "\"SPNDG_VOI_OFFNET_ARPU_M2\",\n",
    "\"SPNDG_VOI_OFFNET_ARPU_M3\",\n",
    "\"USE_LCL_VOI_AMT_M1\",\n",
    "\"USE_LCL_VOI_AMT_M2\",\n",
    "\"USE_LCL_VOI_AMT_M3\",\n",
    "\"SPNDG_VOI_INTRNTL_ARPU_M1\",\n",
    "\"SPNDG_VOI_INTRNTL_ARPU_M2\",\n",
    "\"SPNDG_VOI_INTRNTL_ARPU_M3\",\n",
    "\"SMS_OFFNET_EXP_ARPU_AMT_M1\",\n",
    "\"SMS_OFFNET_EXP_ARPU_AMT_M2\",\n",
    "\"SMS_OFFNET_EXP_ARPU_AMT_M3\",\n",
    "\"SMS_ONNET_EXP_ARPU_AMT_M1\",\n",
    "\"SMS_ONNET_EXP_ARPU_AMT_M2\",\n",
    "\"SMS_ONNET_EXP_ARPU_AMT_M3\",\n",
    "\"EXPDTR_DATA_ARPU_AMT_M1\",\n",
    "\"EXPDTR_DATA_ARPU_AMT_M2\",\n",
    "\"EXPDTR_DATA_ARPU_AMT_M3\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con esto eliminamos todas las columnas que eran innecesarias, y las 2 que encontramos que tenian el mismo valor\n",
    "# para todas sus filas \n",
    "to_remove = to_remove + [x for x in fulldata.columns if fulldata[x].nunique()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.drop(columns=to_remove,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas PREP_RECH_Q_EVT dejando la de granularidad mas chica--ANDREA\n",
    "to_remove_PREP_RECH_Q_EV=['PREP_RECH_Q_EVT_X1',\n",
    "                          'PREP_RECH_Q_EVT_X2',\n",
    "                          'PREP_RECH_Q_EVT_X3',\n",
    "                          'PREP_RECH_Q_MON_12W',\n",
    "                          'PREP_RECH_Q_TUE_12W',\n",
    "                          'PREP_RECH_Q_WEN_12W',\n",
    "                          'PREP_RECH_Q_THUR_12W',\n",
    "                          'PREP_RECH_Q_FRI_12W',\n",
    "                          'PREP_RECH_Q_SAT_12W',\n",
    "                          'PREP_RECH_Q_SUN_12W',\n",
    "                         ]\n",
    "fulldata.drop(columns=to_remove_PREP_RECH_Q_EV,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#de 213 columnas pasamos a 190, good! \n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chequeamos duplicados para todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos si hay duplicados\n",
    "fulldata.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chequeamos la cantidad de filas antes de aplicar drop_duplicates\n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nos aseguramos que la cantidad de registros efectivamente es el mismo\n",
    "fulldata.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora Chequeemos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haremos un heatmap con las primeras 15 columnas identificando donde hay nulos \n",
    "#donde vemos mas blancos es que hay mas nulos\n",
    "sns.heatmap(fulldata[fulldata.columns[0:15]].isnull(), cbar=False)\n",
    "#vemos asi que network_tech tiene muuuchos nulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vamos a hacer lo mismo pero con las primeras 50 columnas\n",
    "sns.heatmap(fulldata[fulldata.columns[0:50]].isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomarwemos una muestra de fulldata de un 30%\n",
    "sampledata = fulldata.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y de esta muestra haremos un heatmap para poder visualizar mejor \n",
    "sns.heatmap(sampledata.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contaremos la cantidad de nulos para cada columna \n",
    "nullcount = {col:fulldata[col].isnull().sum() for col in fulldata.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y haremos una serie con estos valores para graficarlo como grafico de barras\n",
    "missing = pd.Series(nullcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora graficamos valores relativos solamente de las variables que contienen nulos, por eso usamos div\n",
    "missing[missing>0].div(fulldata.shape[0]).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputar Network Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como hay muuuchos nulos en network_tech vamos a trabajar con esto \n",
    "#sacaremos un promedio de sus valores y vemos que la tecnologia con mas ocurrencias es LTE\n",
    "fulldata['NETWORK_TECH'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entonces para cada valor nulo existente en network_tech, le asignaremos el valor LTE, esta es una manera de eliminar nulos\n",
    "fulldata.loc[fulldata['NETWORK_TECH'].isnull(),'NETWORK_TECH']='LTE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenemos la nueva distribucion luego de asignar LTE\n",
    "fulldata['NETWORK_TECH'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora trabajaremos con las columnas DEVICE_MODEL_NAME y DEVICE_VENDOR_NAME que tambien poseen muchos nulos\n",
    "#device model name - distrucion por modelo\n",
    "fulldata['DEVICE_MODEL_NAME'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['DEVICE_VENDOR_NAME'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "observamos que en ambas variables se utiliza el valor NOT_IDENTIFIED para los registros \n",
    "que no poseen datos del device, entonces en este caso, a los valores nulos los \n",
    "reemplazaremos por NOT_IDENTIFIED.\n",
    "'''\n",
    "fulldata.loc[fulldata['DEVICE_MODEL_NAME'].isnull(),'DEVICE_MODEL_NAME']='NOT_IDENTIFIED'\n",
    "fulldata.loc[fulldata['DEVICE_VENDOR_NAME'].isnull(),'DEVICE_VENDOR_NAME']='NOT_IDENTIFIED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asigno en una categoria Others los que no llega a los que los vendors tiene una representacion menor que 100 \n",
    "# creo la nueva categoria Others \n",
    "# contar cuantos hay y los que no llegan a 100 los reemplazo por la categoria Other\n",
    "vendors = fulldata['DEVICE_VENDOR_NAME'].value_counts()\n",
    "vendors_to_replace = vendors[vendors<100].index\n",
    "fulldata.loc[fulldata['DEVICE_VENDOR_NAME'].isin(vendors_to_replace),'DEVICE_VENDOR_NAME'] ='OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago lo mismo con la columna DEVICE_MODEL_NAME\n",
    "# contar cuantos hay y los que no llegan a 100 los reemplazo por la categoria Other\n",
    "models = fulldata['DEVICE_MODEL_NAME'].value_counts()\n",
    "models_to_replace = models[models<100].index\n",
    "fulldata.loc[fulldata['DEVICE_MODEL_NAME'].isin(models_to_replace),'DEVICE_MODEL_NAME'] ='OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#las otras 4 columnas que contienen valores nulos son LAT_PROV_BTS , LON_PROV_BTS, LAT_CITY_BTS y LON_CITY_BTS\n",
    "fulldata[fulldata.columns[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['LAT_PROV_BTS'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['LON_PROV_BTS'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#puedo observar que los mismos registros que no proveen informacion sobre latitutd de la provincia\n",
    "#tampoco lo proveen sobre su longitud. y como no es un numero muy significativo puedo proceder a eliminarlos\n",
    "\n",
    "#haremos el mismo analisis para ver los nulos de latitud y longitud de ciudad\n",
    "fulldata['LAT_CITY_BTS'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['LON_CITY_BTS'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no vemos en las salidas anteriores la cantidad de nulos, entonces llamaremos al metodo isnull y veremos \n",
    "#una sumatoria para ver si la cantidad de nulos es igual\n",
    "fulldata['LAT_CITY_BTS'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['LON_CITY_BTS'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['LAT_PROV_BTS'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['LON_PROV_BTS'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tras ver que es exactamente la misma cantidad de registros los que poseen valores nulos, vamos a proceder a eliminar los \n",
    "#mismos ya que consideramos que no nos modificaran considerablemente la muestra \n",
    "fulldata.drop(fulldata[fulldata['LAT_PROV_BTS'].isnull()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#habiendo eliminado todos los registros, veremos que ya no poseemos mas valores nulos en ninguna de nuestras columnas\n",
    "{col:fulldata[col].isnull().sum() for col in fulldata.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aca se fija cuantos registros hay tras hacer drop NaN hay para corroborar que ya no quedan\n",
    "fulldata.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de Irregulares y Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtengo todas las columnas\n",
    "fulldata.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descripción Estadística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trd_m1 es el trafico de datos mensual\n",
    "fulldata['TRD_M1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['TRD_M1'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos un boxplot con los traficos de datos mensuales para identificar outliers\n",
    "fulldata.boxplot(['TRD_M1','TRD_M2','TRD_M3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora haremos un boxplot y un violinplot solo del trafico de datos mensual del mes 1 \n",
    "fulldata.boxplot('TRD_M1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(y=fulldata['TRD_M1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['SEGMENTATION'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['DEVICE_VENDOR_NAME'].value_counts()[:20].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRATAMIENTO DE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando valores muy extremos\n",
    "fulldata[fulldata['TRD_M1']<=fulldata['TRD_M1'].quantile(0.99)].boxplot('TRD_M1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando valores muy extremos -toma el 99% DE LOS VALORES \n",
    "fulldata[fulldata['TRD_M1']<=fulldata['TRD_M1'].quantile(0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_M1']>fulldata['TRD_M1'].quantile(0.95)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui reemplazomos los outliers por el valor mas alto del quantile 0.95, y de esta forma ya no tenemos outliers\n",
    "fulldata.loc[fulldata['TRD_M1']>fulldata['TRD_M1'].quantile(0.95),'TRD_M1'] = fulldata['TRD_M1'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.boxplot('TRD_M1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el mismo tratamiento de outliers para los traficos de datos mensual 2 y 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antes de eliminar outliers\n",
    "fulldata.boxplot('TRD_M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos cuantos registros hay con valores por debajo del maximo valor del quantile 0.99\n",
    "fulldata[fulldata['TRD_M2']<=fulldata['TRD_M2'].quantile(0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos cuantos registros hay con valores por debajo del maximo valor del quantile 0.95\n",
    "fulldata[fulldata['TRD_M2']>fulldata['TRD_M2'].quantile(0.95)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_M2']<=fulldata['TRD_M2'].quantile(0.99)].boxplot('TRD_M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos a los outliers el valor mas alto del quantile 0.95\n",
    "fulldata.loc[fulldata['TRD_M2']>fulldata['TRD_M2'].quantile(0.95),'TRD_M2'] = fulldata['TRD_M2'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#despues de eliminar outliers\n",
    "fulldata.boxplot('TRD_M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos las estadísticas de TRD_M3\n",
    "fulldata['TRD_M3'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#antes de eliminar outliers\n",
    "fulldata.boxplot('TRD_M3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos cuantos registros hay con valores por debajo del maximo valor del quantile 0.99\n",
    "fulldata[fulldata['TRD_M3']<=fulldata['TRD_M3'].quantile(0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos cuantos registros hay con valores por debajo del maximo valor del quantile 0.95\n",
    "fulldata[fulldata['TRD_M3']>fulldata['TRD_M3'].quantile(0.95)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos a los outliers el valor mas alto del quantile 0.95\n",
    "fulldata.loc[fulldata['TRD_M3']>fulldata['TRD_M3'].quantile(0.95),'TRD_M3'] = fulldata['TRD_M3'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#despues de eliminar outliers\n",
    "fulldata.boxplot('TRD_M3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos ver los traficos de datos mensuales de los 3 meses ahora sin outliers \n",
    "fulldata.boxplot(['TRD_M1','TRD_M2','TRD_M3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haremos el mismo tratamiento de outliers para el trafico de datos en streaming en los meses 1, 2 y 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['TRD_STR_M1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['TRD_STR_M1'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(fulldata['TRD_STR_M1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos suprimiendo valores muy extremos -toma el 99% DE LOS VALORES \n",
    "fulldata[fulldata['TRD_STR_M1']<=fulldata['TRD_STR_M1'].quantile(0.99)].boxplot('TRD_STR_M1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_STR_M1']<=fulldata['TRD_STR_M1'].quantile(0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_STR_M1']>fulldata['TRD_STR_M1'].quantile(0.95)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aquí reemplazamos los outliers con el valor del quantile 0.95\n",
    "fulldata.loc[fulldata['TRD_STR_M1']>fulldata['TRD_STR_M1'].quantile(0.95),'TRD_STR_M1'] = fulldata['TRD_STR_M1'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.boxplot('TRD_STR_M1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el mismo tratamiento de outliers para TRAFICO DE DATOS MENSAJES POR INTERENT MENSUAL 1, 2 y 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos las estadísticas de 'TRD_SN_M1'\n",
    "fulldata['TRD_SN_M1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el boxplot para identificar outliers\n",
    "fulldata.boxplot('TRD_SN_M1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_SN_M1']<=fulldata['TRD_SN_M1'].quantile(0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_SN_M1']>fulldata['TRD_SN_M1'].quantile(0.95)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos suprimiendo valores muy extremos -toma el 95% DE LOS VALORES \n",
    "fulldata[fulldata['TRD_SN_M1']<=fulldata['TRD_SN_M1'].quantile(0.95)].boxplot('TRD_SN_M1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que suprimiendo los valores del quantile 0.95 estamos modificando mucho la media del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a reemplazar outliers con el valor del quantile 0.99\n",
    "fulldata.loc[fulldata['TRD_SN_M1']>fulldata['TRD_SN_M1'].quantile(0.99),'TRD_SN_M1'] = fulldata['TRD_SN_M1'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribución tras eliminar outliers, manteniendo sin grandes cambios los datos estadísticos del data frame\n",
    "fulldata.boxplot('TRD_SN_M1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos las estadísticas de 'TRD_SN_M2'\n",
    "fulldata['TRD_SN_M2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el boxplot para identificar outliers\n",
    "fulldata.boxplot('TRD_SN_M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos suprimiendo valores muy extremos -toma el 95% DE LOS VALORES \n",
    "fulldata[fulldata['TRD_SN_M2']<=fulldata['TRD_SN_M2'].quantile(0.95)].boxplot('TRD_SN_M2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que suprimiendo los valores del quantile 0.95 estamos modificando mucho la media del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a reemplazar outliers con el valor del quantile 0.99\n",
    "fulldata.loc[fulldata['TRD_SN_M2']>fulldata['TRD_SN_M2'].quantile(0.99),'TRD_SN_M2'] = fulldata['TRD_SN_M2'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribución tras eliminar outliers, manteniendo sin grandes cambios los datos estadísticos del data frame\n",
    "fulldata.boxplot('TRD_SN_M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos las estadísticas de 'TRD_SN_M3'\n",
    "fulldata['TRD_SN_M3'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el boxplot para identificar outliers\n",
    "fulldata.boxplot('TRD_SN_M3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos suprimiendo valores muy extremos -toma el 95% DE LOS VALORES \n",
    "fulldata[fulldata['TRD_SN_M3']<=fulldata['TRD_SN_M3'].quantile(0.95)].boxplot('TRD_SN_M3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que suprimiendo los valores del quantile 0.95 estamos modificando mucho la media del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a reemplazar outliers con el valor del quantile 0.99\n",
    "fulldata.loc[fulldata['TRD_SN_M3']>fulldata['TRD_SN_M3'].quantile(0.99),'TRD_SN_M3'] = fulldata['TRD_SN_M3'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribución tras eliminar outliers, manteniendo sin grandes cambios los datos estadísticos del data frame\n",
    "fulldata.boxplot('TRD_SN_M3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer lo mismo pero con el TRAFICO DE DATOS MENSAJES POR INTERENT MENSUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(fulldata['TRD_IM_M1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['TRD_IM_M1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando valores muy extremos -toma el 99% DE LOS VALORES \n",
    "fulldata[fulldata['TRD_IM_M1']<=fulldata['TRD_IM_M1'].quantile(0.95)].boxplot('TRD_IM_M1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_IM_M1']<=fulldata['TRD_IM_M1'].quantile(0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[fulldata['TRD_IM_M1']>fulldata['TRD_IM_M1'].quantile(0.95)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.loc[fulldata['TRD_IM_M1']>fulldata['TRD_IM_M1'].quantile(0.95),'TRD_IM_M1'] = fulldata['TRD_IM_M1'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fulldata.boxplot('TRD_IM_M1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer lo mismo con el MONTO DE RECARGAS ACUMULADAS MENSUALES--ANDRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vamos a comparara los montos de recargas acumuladas Mensuales - desp comparo cada una contra el target --ANDREA\n",
    "fulldata.boxplot(['PREP_RECH_AMT_X1','PREP_RECH_AMT_X2','PREP_RECH_AMT_X3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer lo mismo con el TRAFICO DE DATOS DE OTRAS FUENTES MENSUALES-- ANDRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vamos a comparar trafico de datos de otras fuentes mensual --ANDREA\n",
    "fulldata.boxplot(['TRD_OTH_M1','TRD_OTH_M2','TRD_OTH_M3'])\n",
    "#Los borramos porque estan inconsistennnteeees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminas las columnas TRAFICO DE DATOS DE OTRAS FUENTES MENSUALES porque como vimos en el \n",
    "grafico anterior son inconsistentes-- ANDRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos columnas con datos incorrectos -- VER GRAFICO ANDRE \n",
    "column_incorrect = ['PREP_RECH_NDAYS_LASTRECH_12W',\n",
    "                   'TRD_OTH_M1',\n",
    "                   'TRD_OTH_M2',\n",
    "                   'TRD_OTH_M3']\n",
    "fulldata.drop(columns=column_incorrect,inplace=True)#--ANDREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['TRS_ONNET_SMS_M1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fulldata[fulldata.columns[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos los datos unicos que contienen las primeras 20 columnas\n",
    "fulldata['VALUE_SEGMENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['SEGMENTATION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['MICROSEGMENTATION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['DEVICE_VENDOR_NAME'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observa el tipo de dato de activation date y luego lo convierte a datetime- es tipo objeto\n",
    "fulldata['COMMERCIAL_ACTIVATION_DATE'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['COMMERCIAL_ACTIVATION_DATE']\n",
    "#podemos ver que se representan las fechas como string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entonces realizaremos una transformacion para tratarlas como data \n",
    "fulldata['COMMERCIAL_ACTIVATION_DATE'] = pd.to_datetime(fulldata['COMMERCIAL_ACTIVATION_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuando consultamos los valores de value_segment, vemos que los clientes se dividen en 4 categorias\n",
    "#sera mas facil trabajar con la categoria considerandolo como un valor numerico, sin importa como se llame dicha categoria\n",
    "fulldata['VALUE_SEGMENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['VALUE_SEGMENT'] = pd.to_numeric(fulldata['VALUE_SEGMENT'].str.split(' - ').str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos realizar el mismo trabajo para el caso de la columna SEGMENTATION, nos quedamos con los valores numericos \n",
    "#y no con las siglas de cada una de ellas \n",
    "fulldata['SEGMENTATION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['SEGMENTATION'] = pd.to_numeric(fulldata['SEGMENTATION'].str.split('-').str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos como nos queda nuestro data set luego de las respectivas transformaciones realizadas\n",
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veremos en un grafico la cantidad de recargas acumuladas mensuales en el mes 1 --ANDRE TUVE QUE CAMBIARA ACA PORQUE BORRE EL MES\n",
    "sns.distplot(fulldata['PREP_RECH_Q_EVT_W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(fulldata['PREP_RECH_Q_EVT_W1'],shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparo el target de los que se van con el value segment \n",
    "fulldata[fulldata['Target']==1]['VALUE_SEGMENT'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumamos los full data y luego borramos las columnas de PACK_DATA_EXP_Wi\n",
    "fulldata['TOTAL_EXP_PACKDATA_W'] = fulldata[fulldata.columns[178:188]].sum(axis=1)\n",
    "#elimino lo que ya sume\n",
    "fulldata.drop(columns=[x for x in fulldata.columns if 'PACK_DATA_EXP_W' in x],inplace=True)\n",
    "fulldata['TOTAL_EXP_PACKDATA_W']=fulldata['TOTAL_EXP_PACKDATA_W']<1\n",
    "fulldata['TOTAL_EXP_PACKDATA_W'] = fulldata['TOTAL_EXP_PACKDATA_W'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grafico donde relacionamos la cantidad de pack de datos mensuales con el trafico de datos de mensaje por internet \n",
    "#mensual, en el mes 1\n",
    "sns.jointplot(x=fulldata['PACK_DATA_Q_X1'], y=fulldata['TRD_IM_M1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRD_M1 = trafico de datos mensual\n",
    "#TRD_STR_M1 = trafico de datos en streaming mensual\n",
    "#TRD_SN_M1 = trafico de datos en redes sociales mensual\n",
    "#TRD_IM_M1 = trafico de datos de mensajes por internet mensual\n",
    "\n",
    "sns.pairplot(fulldata[['TRD_M1','TRD_STR_M1','TRD_SN_M1','TRD_IM_M1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANDREA - Analizamos la variable TERNURE_CUSTOMER\n",
    "fulldata.boxplot(['TENURE_CUSTOMER']) \n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos como queda el grafico si eliminariamos valores muy extremos\n",
    "fulldata[fulldata['TENURE_CUSTOMER']<=fulldata['TENURE_CUSTOMER'].quantile(0.99)].boxplot('TENURE_CUSTOMER')\n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.loc[fulldata['TENURE_CUSTOMER']>fulldata['TENURE_CUSTOMER'].quantile(0.99)]=fulldata['TENURE_CUSTOMER'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANDRE LAST\n",
    "fulldata.boxplot(['TENURE_CUSTOMER'])\n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Comparo Antiguedad contra el target 0 y 1 --ANDRE\n",
    "Tenure_1 = fulldata[fulldata[\"Target\"] == 1][\"TENURE_CUSTOMER\"].value_counts(normalize=True).sort_index()\n",
    "Tenure_0 = fulldata[fulldata[\"Target\"] == 0][\"TENURE_CUSTOMER\"].value_counts(normalize=True).sort_index()\n",
    "#fulldata[fulldata['SUSCRIBER_KEY']=='E_68006527_20110525'][\"TENURE_CUSTOMER\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --ANDRE\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Target1- Se va',y=Tenure_1.values,x=Tenure_1.index),\n",
    "    go.Bar(name='Target0- Se queda',y=Tenure_0.values,x=Tenure_0.index)\n",
    "])\n",
    "fig.update_layout(xaxis=dict(range=[0,60]))\n",
    "fig.update_layout(barmode='group')\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Comparasion Targets con Tenure Customer\",\n",
    "    xaxis_title=\"Antiguedad cliente meses\",\n",
    "    yaxis_title=\"Fr. Relativa\",\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANDREA - Analizamos la variable TERNURE_CUSTOMER_BL- Antiguedad desde el primer gasto\n",
    "fulldata.boxplot(['TENURE_CUSTOMER_BL']) \n",
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Comparo Antiguedad contra el target 0 y 1 --ANDRE\n",
    "TenureBL_1 = fulldata[fulldata[\"Target\"] == 1][\"TENURE_CUSTOMER_BL\"].value_counts(normalize=True).sort_index()\n",
    "TenureBL_0 = fulldata[fulldata[\"Target\"] == 0][\"TENURE_CUSTOMER_BL\"].value_counts(normalize=True).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ind=np.arange(fulldata['TENURE_CUSTOMER'].nunique()) \n",
    "#width = 0.40  # ancho de las barras\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Target1- Se va',y=TenureBL_1.values,x=TenureBL_1.index),\n",
    "    go.Bar(name='Target0- Se queda',y=TenureBL_0.values,x=TenureBL_0.index)\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(xaxis=dict(range=[0,60]))\n",
    "fig.update_layout(barmode='group')\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Comparasion Targets con Antiguedad desde que hizo el primer gasto\",\n",
    "    xaxis_title=\"Antiguedad desde que hizo el primer gasto\",\n",
    "    yaxis_title=\"Fr. Relativa\",\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comparasion entre  TENURE_CUSTOMER y  TENURE_CUSTOMER_BL SON IGUALES LA ELIMINO A TERNURE_COSTUMER_BL\n",
    "\n",
    "for_pairplot= fulldata[[\"TENURE_CUSTOMER\", \"TENURE_CUSTOMER_BL\"]]\n",
    "for_pairplot=for_pairplot.sample(1000)\n",
    "sns.pairplot(for_pairplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Borro la columna TENURE_CUSTOMER_BL\n",
    "fulldata.drop(columns=\"TENURE_CUSTOMER_BL\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparacion entre Montos pack voz mensual y Cantidad de pack voz mensual  PACK_VOICE_Q_X1 PACK_VOICE_Q_X2 PACK_VOICE_Q_X3 PACK_VOICE_AMT_X1 PACK_VOICE_AMT_X2 PACK_VOICE_AMT_X3 --ANDRE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comparacion entre Montos pack voz mensual y Cantidad de pack voz mensual  PACK_VOICE_Q_X1 PACK_VOICE_Q_X2 PACK_VOICE_Q_X3 PACK_VOICE_AMT_X1 PACK_VOICE_AMT_X2 PACK_VOICE_AMT_X3\n",
    "f,ax = plt.subplots(figsize=(10, 6))\n",
    "g = sns.heatmap(fulldata[[\"PACK_VOICE_Q_X1\", \"PACK_VOICE_Q_X2\", \"PACK_VOICE_Q_X3\", \"PACK_VOICE_AMT_X1\",\n",
    "                     \"PACK_VOICE_AMT_X2\", \"PACK_VOICE_AMT_X3\"]].corr(),\n",
    "            annot=True, linewidths=.5, fmt= '.1f', ax=ax)\n",
    "plt.suptitle(\"Montos Pack voz mensual y Cantidad de pack voz mensual \\nCorrelation Heatmap\",\n",
    "               fontsize=16, weight=\"bold\", y=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que tienen una alta correlacion elimino las los montos\n",
    "fulldata.drop(columns=['PACK_VOICE_AMT_X1','PACK_VOICE_AMT_X1','PACK_VOICE_AMT_X1'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparacion entre Montos pack datos mensual y Cantidad de pack datos mensual  PACK_DATA_Q_X1 PACK_DATA_Q_X2 PACK_DATA_Q_X3  PACK_VOICE_AMT_X1  PACK_VOICE_AMT_X2  PACK_VOICE_AMT_X3 --ANDRE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comparacion entre Montos pack voz mensual y Cantidad de pack voz mensual  PACK_DATA_Q_X1 PACK_DATA_Q_X2 PACK_DATA_Q_X3 PACK_DATA_AMT_X1 PACK_DATA_AMT_X2 PACK_DATA_AMT_X3\n",
    "\n",
    "f,ax = plt.subplots(figsize=(10, 6))\n",
    "g = sns.heatmap(fulldata[[\"PACK_DATA_Q_X1\", \"PACK_DATA_Q_X2\", \"PACK_DATA_Q_X3\", \"PACK_DATA_AMT_X1\",\n",
    "                     \"PACK_DATA_AMT_X2\", \"PACK_DATA_AMT_X3\"]].corr(),\n",
    "            annot=True, linewidths=.5, fmt= '.1f', ax=ax)\n",
    "plt.suptitle(\"Montos Pack datos mensual y Cantidad de pack datos mensual \\nCorrelation Heatmap\",\n",
    "               fontsize=16, weight=\"bold\", y=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que tienen una alta correlacion elimino las los montos\n",
    "fulldata.drop(columns=['PACK_DATA_AMT_X1','PACK_DATA_AMT_X2','PACK_DATA_AMT_X3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparacion entre Montos pack datos mensual y Cantidad de pack datos mensual  PACK_SMS_Q_X1  PACK_SMS_Q_X2  PACK_SMS_Q_X3  PACK_SMS_AMT_X1  PACK_SMS_AMT_X2  PACK_SMS_AMT_X3 --ANDRE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Comparacion entre Montos pack mensual y Cantidad de pack SMS  PACK_SMS_Q_X1 PACK_SMS_Q_X2 PACK_SMS_Q_X3 PACK_SMS_AMT_X1 PACK_SMS_AMT_X2 PACK_SMS_AMT_X3\n",
    "\n",
    "f,ax = plt.subplots(figsize=(10, 6))\n",
    "g = sns.heatmap(fulldata[[\"PACK_SMS_Q_X1\", \"PACK_SMS_Q_X1\", \"PACK_SMS_Q_X1\", \"PACK_SMS_AMT_X1\",\n",
    "                     \"PACK_SMS_AMT_X2\", \"PACK_SMS_AMT_X3\"]].corr(),\n",
    "            annot=True, linewidths=.5, fmt= '.1f', ax=ax)\n",
    "plt.suptitle(\"Montos Pack SMS mensual y Cantidad de pack SMS mensual \\nCorrelation Heatmap\",\n",
    "               fontsize=16, weight=\"bold\", y=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vemos que tienen una alta correlacion elimino las los montos--ANDREUPDATED\n",
    "#fulldata.drop(columns=['PACK_DATA_AMT_X1','PACK_DATA_AMT_X2','PACK_DATA_AMT_X3'], inplace=True)\n",
    "#no tiene valores borro todo \n",
    "plt.figure(figsize=(15,7));\n",
    "\n",
    "plt.hist(fulldata[\"PACK_SMS_Q_X1\"], bins=40, alpha=0.5, label='Q SMS X1', color = \"black\") \n",
    "plt.hist(fulldata[\"PACK_SMS_Q_X2\"], bins=40, alpha=0.5, label='Q SMS X2', color = \"brown\") \n",
    "plt.hist(fulldata[\"PACK_SMS_Q_X3\"], bins=40, alpha=0.5, label='Q SMS X2', color = \"red\") ;\n",
    "\n",
    "plt.title('Cantidad mensuales de SMS');\n",
    "\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Cantidad de recargas SMS');\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.grid(color='grey', linestyle='solid');\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-ANDRENEW\n",
    "plt.figure(figsize=(15,7));\n",
    "\n",
    "plt.hist(fulldata[\"PACK_SMS_AMT_X1\"], bins=40, alpha=0.5, label='Monto SMS X1', color = \"green\") \n",
    "plt.hist(fulldata[\"PACK_SMS_AMT_X1\"], bins=40, alpha=0.5, label='Monto SMS X2', color = \"grey\") \n",
    "plt.hist(fulldata[\"PACK_SMS_AMT_X1\"], bins=40, alpha=0.5, label='Monto SMS X3', color = \"pink\");\n",
    "\n",
    "plt.title('Monto mensuales de SMS');\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Monto de recargas SMS');\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.grid(color='grey', linestyle='solid');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tiene valores borro esas columnas --ANDRE\n",
    "fulldata.drop(columns=['PACK_SMS_Q_X1','PACK_SMS_Q_X2','PACK_SMS_Q_X3','PACK_SMS_AMT_X1','PACK_SMS_AMT_X2','PACK_SMS_AMT_X3'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #fulldata['TRS_ONNET_SMS_M1'].describe()\n",
    "(fulldata[[x for x in fulldata.columns if 'SMS' in x]]==0).sum()/fulldata.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis datos SMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trafico de SMS en la misma red--ANDREUPDATED\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(fulldata['TRS_ONNET_SMS_M1'], bins=80, alpha=0.5, label='Trafico SMS M1', color = \"purple\");\n",
    "plt.hist(fulldata['TRS_ONNET_SMS_M2'], bins=80, alpha=0.5, label='Trafico SMS M2', color = \"green\");\n",
    "plt.hist(fulldata['TRS_ONNET_SMS_M3'], bins=80, alpha=0.5, label='Trafico SMS M3', color = \"blue\");\n",
    "plt.title('Trafico de mensajes en la misma red');\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Trafico SMS misma red');\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.grid(color='grey', linestyle='solid');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como son muy cercanos a 0 - borro estos campos TRS_ONNET_SMS_M1 TRS_ONNET_SMS_M2 TRS_ONNET_SMS_M3\n",
    "fulldata.drop(columns=['TRS_ONNET_SMS_M1','TRS_ONNET_SMS_M2','TRS_ONNET_SMS_M3'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trafico de mensajes en otras redes --ANDREUPDATED\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(fulldata['TRS_OFFNET_SMS_M1'], bins=80, alpha=0.5, label='Trafico SMS OFF M1', color = \"yellow\");\n",
    "plt.hist(fulldata['TRS_OFFNET_SMS_M2'], bins=80, alpha=0.5, label='Trafico SMS OFF M1', color = \"green\");\n",
    "plt.hist(fulldata['TRS_OFFNET_SMS_M3'], bins=80, alpha=0.5, label='Trafico SMS OFF M1', color = \"blue\");\n",
    "plt.title('Trafico de mensajes en otras redes');\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Trafico SMS otras redes');\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.grid(color='grey', linestyle='solid');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como son muy cercanos a 0 - borro estos campos TRS_OFFNET_SMS_M1 TRS_OFFNET_SMS_M2 TRS_OFFNET_SMS_M3\n",
    "fulldata.drop(columns=['TRS_OFFNET_SMS_M1','TRS_OFFNET_SMS_M2','TRS_OFFNET_SMS_M3'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[['TRD_M1','TRD_STR_M1','TRD_SN_M1','TRD_IM_M1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata[['TRD_STR_M1','TRD_SN_M1','TRD_IM_M1']].div(1024).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = fulldata.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,60))\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,60))\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        annot = True, vmin=-1, vmax=1, center= 0,\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kot = corr[corr>=.6]\n",
    "plt.figure(figsize=(60,60))\n",
    "sns_plot = sns.heatmap(kot, cmap=\"Greens\")\n",
    "sns_plot.figure.savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test\n",
    "Debemos separar el modelo en 2 partes:\n",
    "    * Conjunto entrenamiento \n",
    "    * Conjunto de test\n",
    "Entonces a partir del conjunto de entrenamiento, entrenamos el modelo, y una vez que conseguimos un modelo predictivo, con el conjunto de test testeamos el modelo para ver que tan bien funciona\n",
    "\n",
    "Necesitamos hacer una division de lo que se considera datos de entrenamiento (data) y el resultado a obtener (tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuestro tag estara dado por la columna target, al que llamaremos y \n",
    "y = fulldata['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que crear la variable x que contendra la informacion para el entrenamiento del modelo (data)\n",
    "\n",
    "Tenemos que quitar la columna SUSCRIBER_KEY que es una columna de valores unicos y que solo sirve para identificar a cada linea, pero no para entrenar el modelo. Y obviamente tampoco tiene sentido poner la columna Target dentro de los datos de \n",
    "entrenamiento, sino el modelo va a conocer perfectamente que persona abandona o no el servicio\n",
    "\n",
    "Y solamente tomamos en cuenta las columnas que son numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = fulldata.select_dtypes(include=['int64','float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in fulldata.columns if col not in [ 'SUSCRIBER_KEY', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fulldata[columns]\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora nos quedamos con los valores de cada variable\n",
    "#values pasa de serie a array\n",
    "y = y.values\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos las dos variables X e y, debemos realizar una division del dataset en un dataset de entrenamiento y uno de testeo\n",
    "\n",
    "Usaremos el metodo Train Test Split, el cual se encarga de dividir nuestro conjunto original en un conjunto de entrenamiento y un conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # cargamos el metodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos el conjunto entrenamiento y test con el metodo train_test_split y se lo asignamos a las distintas variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "#por default el conjunto se separara en 75% para el train y 25% para el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que como separamos la variable X en train y test, la suma de registros de X_train y X_test \n",
    "dara la cantidad de registros de X. En el caso de la variable y ocurriria exactamente igual.\n",
    "\n",
    "A su vez, X_train tendra la misma cantidad de registros o filas que y_train, y X_test la misma que y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizaremos xgboost como modelo predictivo\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imports para entrenamiento, predicción y evaluación del modelo ####\n",
    "#### NO QUITAR ####\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#estas herramientas nos permiten calcular metricas del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train,y_train):\n",
    "    \"\"\"\n",
    "    Función para entrenar el modelo.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    \n",
    "    X_train: pd.DataFrame\n",
    "        Dataset de Train, listo para entrenar y sin tag\n",
    "        \n",
    "    y_train: pd.DataFrame\n",
    "        Dataset de tag, es el tag correspondiente al dataset de train.\n",
    "        \n",
    "    Return\n",
    "    ----------\n",
    "    Modelo Entrenado.\n",
    "    \n",
    "    \"\"\"\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    #instanciamos el clasificador xgb\n",
    "    \n",
    "    print(\"Comienza entrenamiento del modelo XGBoost\")\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    #el metodo fit llama al modelo matematico que entrenara el modelo \n",
    "    #xgb model ahora va a ser un modelo entrenado\n",
    "    \n",
    "    print(\"Entrenamiento finalizado\\n\")\n",
    "\n",
    "    print(\"Haciendo las predicciones\\n\\n\")\n",
    "\n",
    "    #con este modelo ya entrenado llamo al metodo predict\n",
    "    XGB_preds = xgb_model.predict(X_test)\n",
    "    #comparo mis predicciones con el valor real que tengo guardo en y_test \n",
    "    print(classification_report(y_test, XGB_preds))\n",
    "    print(confusion_matrix(y_test, XGB_preds))\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_to_predict, xgb_model):\n",
    "    \"\"\"Funcion para hacer el entrenamiento del modelo y guardarlo en un archivo .pkl\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "    data_to_predict : pd.DataFrame\n",
    "        DataFrame listo para predecir, con las mismas transformaciones que el de entrenamiento.\n",
    "        \n",
    "    xgb_model : xgb.XGBClassifier\n",
    "        Modelo entrenado de XGBoost\n",
    "\n",
    "    Return\n",
    "    -----------\n",
    "    Dataframe de 3 columnas, la identificacion del cliente, la prediccion de la clase y la probabilidad de que el cliente\n",
    "    permanezca en el servicio.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n-------------------------\")\n",
    "    print(\"Ingreso a la funcion de prediccion\\n\")\n",
    "\n",
    "    XGB_preds = xgb_model.predict_proba(X)\n",
    "    #si en vez de un predict proba hacemos un predict nos daria como resultado 0 y 1 directamente, redondeando\n",
    "    \n",
    "    return XGB_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la prediccion del modelo La metrica que mas interesa ver es f1-score .. \n",
    "vemos qeue el modelo predice mejor 0s que 1s, tiene sentido porque tenemos mas 0s que 1s entre los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = predict(X_test,modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado\n",
    "#podemos ver un array con las probabilidades de que cada registro valga 0 o 1\n",
    "#por ejemplo en el primer registro tenemos 86% de probabilidades de que valga 0, y 13% de que valga 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.DataFrame(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podriamos determinar por ejemplo que tengan 1 aquellos que tengan un valor de probabilidad mayor a 0.6 \n",
    "(resultado[1] > 0.6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(resultado).to_csv('resultado.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
